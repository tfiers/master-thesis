\sectionp{1p}{Data-driven algorithms}
\label{sec:data-driven-algorithms}

In this and the following chapter, we describe \emph{supervised}, or data-driven SWR detection algorithms: they require training data $\z\train_t$, and an associated labelling $y\train_t$ which marks the presence of an SWR event in $\z\train_t$, for every discrete time sample $t$. For example, $y_t \in \{0, 1\}$, with $y_t = 1$ when the corresponding input sample $\z_t$ is part of an SWR segment, and $y_t = 0$ when it is not.

The problem of obtaining such a labelling $y_t$ for some recording data $\z_t$ is the topic of \cref{ch:offline}. Training labels can be obtained either by human expert labellers, or by using an automated \emph{offline} SWR detection algorithm, where we assume that the automated labelling corresponds well to a supposed human expert labelling. In this thesis, we use the automated labelling method of \cref{ch:offline} to generate target labellings $y\train_t$.

Before a supervised algorithm can be used for real-time detection, its parameters have to be `tuned'. This is done using a training dataset $(\z\train_t, y\train_t)$, during the so called \emph{training phase}. Parameters are changed such that the algorithm's output $o_t$ for an input $\z\train_t$ matches the target labelling $y\train_t$ well. \Cref{sec:LSM,sec:RNN-optim} describe how this tuning can be done for two concrete detection algorithms.

The hope is that the trained algorithm also performs well on input data $\z\test_t$ not part of the training set. That is, that the algorithm has good \emph{generalization performance}. When this is not the case and the algorithm is tuned so that it only performs well on the training data, we say that the algorithm has been \emph{overfit}. Often, so called \emph{regularization} methods exist to discourage overfitting on the training data.
% Some example regularization methods are discussed in \cref{sec:GEVD-regularization,sec:RNN-regularization}.
