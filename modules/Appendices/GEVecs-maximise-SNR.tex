\chapter{Generalized eigenvectors maximize signal-to-noise}
\label{apx:GEvecs-maximise-SNR}

In this appendix, we show that the weight vector that maximizes the ratio of signal to noise variance (i.e. the solution $\what$ to \cref{eq:argmax_R}) is equivalent to the first generalized eigenvector $\w_1$ of the ordered pair of covariance matrices $(\Rss, \Rnn)$ (as defined in \cref{sec:generalized-eigenproblem}).

This ratio of variances in \cref{eq:argmax_R} is a quotient of quadratic forms, namely the so called ``generalized Rayleigh quotient'' of $(\Rss, \Rnn)$.

Formally, the generalized Rayleigh quotient of a non-zero vector $\w \in \reals^N$ and the ordered, symmetric matrix pair $(\A,\B)$ is the scalar $r(\w)$ defined as:
%
\begin{equation}
\label{eq:Rayleigh}
r(\w) = \frac{\w^T \A \w}
             {\w^T \B \w}
\end{equation}

We must then prove the following:



\section{Theorem}

The generalized eigenvector $\w_1$ corresponding to the largest generalized eigenvalue $\lambda_1$ of $(\A,\B)$, is also the vector $\what$ that maximises the generalized Rayleigh quotient $r(\w)$ of $(\A,\B)$.




\section{Proof}

As a first step, we will show that if $\what$ is the maximum of $r(\w)$, that it is indeed an eigenvector of $(\A,\B)$. In the second step, we will show that the largest eigenvalue $\lambda_1$ of $(\A,\B)$ corresponds to the maximum of $r(\w)$.

If $\what$ is a maximum of $r(\w)$, then
\begin{equation}
\label{eq:critical}
\grad{r(\what) = \vb{0}}.
\end{equation}

Working out the partial derivatives that comprise the gradient of $r(\w)$, we find:
\begin{align*}
\grad{r(\w)} &= \frac{2 \A \w \qty(\w^T \B \w) 
                      - 2 \B \w \qty(\w^T \A \w)}
                     {\qty(\w^T \B \w)^2}
\end{align*}

With \cref{eq:critical}, we then have the following condition for our maximising vector $\what$:
\[
2 \A \what \qty(\what^T \B \what) 
    &= 2 \B \what \qty(\what^T \A \what)
\]
or
\begin{align*}
\A \what &= \frac{\what^T \A \what}
                 {\what^T \B \what} \; \B \what  \\[1em]
\A \what &= r(\what) \; \B \what
\end{align*}
This is the generalized eigenvalue/eigenvector definition (\cref{eq:generalized-eigenproblem}) for $\w_i = \what$ and $\lambda_i = r(\what)$.

We have thus shown that if $\what$ is a maximum of $r(\w)$, that it is an eigenvector of $(\A,\B)$, with $r(\what)$ its corresponding eigenvalue.

As the second step, we now show that $r(\what)$ is the \emph{largest} eigenvalue of $(\A,\B)$. We follow the reasoning of \citeauthor{Trefethen1997}, who prove a related result for the ordinary Rayleigh quotient \cite[p. 204]{Trefethen1997}.

We will rewrite the generalized Rayleigh quotient $r(\w)$ by writing the arbitrary vector $\w$ as a linear combination of the generalized eigenvectors $\w_i$ of $(\A,\B)$: $\w = \sum_i c_i \w_i$. Then:
\begin{align*}
r(\w) &= \frac{\qty(\sum_i c_i \w_i)^T \A \qty(\sum_i c_i \w_i)}
              {\qty(\sum_i c_i \w_i)^T \B \qty(\sum_i c_i \w_i)} \\[1em]
              % 
      &= \frac{\sum_i c_i^2 \w_i^T \A \w_i}
              {\sum_i c_i^2 \w_i^T \B \w_i} \\[1em]
              % 
      &= \frac{\sum_i c_i^2 \lambda_i \w_i^T \B \w_i}
              {\sum_i c_i^2 \w_i^T \B \w_i}.
\end{align*}

Generalized eigenvectors are defined up to a scaling factor. We may therefore define our $\w_i$ to be scaled such that $\w_i^T \B \w_i = 1$. We then have:
\[
r(\w) = \frac{\sum_i c_i^2 \lambda_i}{\sum_i c_i^2}.
\]
%
Each generalized Rayleigh quotient is thus a convex combination of generalized eigenvalues $\lambda_i$. The maximum of a convex combination of one-dimensional points is obtained in the largest of these points. If $\lambda_1$ is thus the largest generalized eigenvalue of $(\A,\B)$, then $\max{r(\w)} = \lambda_1$.

We have thus shown that $\argmax r(\w) = \w_1$, where $\w_1$ is an eigenvector of $(\A,\B)$, and that its corresponding eigenvalue $\lambda_1 = \max r(\w)$ is the largest of the eigenvalues of $(\A,\B)$.

\qed
