\sectionp{1p}{Data-driven algorithms}
\label{sec:data-driven-algorithms}

In this and the following chapter, we describe \emph{supervised}, or \emph{data-driven} detection algorithms: they require training data $\z\train_t$, and an associated labelling $y\train_t$ which marks when there is an event present in $\z\train_t$. We arbitrarily define $y_t \in \{0, 1\}$, with $y_t = 1$ when the corresponding input sample $\z_t$ is part of an SWR segment, and $y_t = 0$ when it is not. The problem of obtaining a reference target labelling $y_t$ for some recording data $\z_t$ is the same as marking SWR segments for offline analysis or for offline evaluation of an online detection algorithm. As described in \cref{sec:offline}, this can be done either by human expert labellers, or by using an automated \emph{offline} SWR detection algorithm, where we assume that the automated labelling would correspond well to a human expert labelling. In this thesis, we use the automated labelling method of \cref{sec:offline} to generate target labellings $y\train_t$.

Before a supervised algorithm can be used for real-time detection, its parameters have to be `tuned'. This is done using a training dataset $(\z\train_t, y\train_t)$, during the so called \emph{training phase}. Parameters are changed such that the algorithm's output $o_t$ for an input $\z\train_t$ matches the target labelling $y\train_t$ well. \Cref{sec:LSM,sec:RNN-optim} describe how this tuning can be done for two concrete detection algorithms.

The hope is that the trained algorithm also performs well on input data $\z\test_t$ not part of the training set. That is, that the algorithm has good \emph{generalization performance}. When this is not the case and the algorithm is tuned so that it only performs well on the training data, we say that the algorithm has been \emph{overfit}. Often, so called \emph{regularization} methods exist to discourage overfitting on the training data. Some example regularization methods are discussed in \cref{sec:GEVD-regularization,sec:RNN-regularization}.
